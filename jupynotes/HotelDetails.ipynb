{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import selenium.webdriver as webdriver\n",
    "import selenium.webdriver.support.ui as ui\n",
    "import re\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "\n",
    "start_time = time.time()\n",
    "ret = 1\n",
    "page_num = 1\n",
    "rating = []\n",
    "name = []\n",
    "review_date = []\n",
    "title = []\n",
    "review = []\n",
    "all_data = dict()\n",
    "url = Embassy_Suites\n",
    "driver = webdriver.Chrome()   \n",
    "    \n",
    "while ret:\n",
    "    print(url)\n",
    "    \n",
    "    driver.get(url)\n",
    "#     wait = ui.WebDriverWait(driver,10)\n",
    "    \n",
    "    mores = driver.find_elements_by_css_selector('span.taLnk.ulBlueLinks')\n",
    "    for more in mores:\n",
    "        driver.execute_script(\"arguments[0].click()\", more) \n",
    "\n",
    "    time.sleep(10)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'lxml')   \n",
    "    \n",
    "    data = dict()\n",
    "\n",
    "    for mgr in soup.find_all(\"div\", {'class':'mgrRspnInline'}): \n",
    "        mgr.decompose()\n",
    "    for cnt in soup.find_all(\"div\", {'class':'content_block answers_block tabs_answers scroll_tabs'}):\n",
    "        cnt.decompose()    \n",
    "\n",
    "    for sp in soup.find_all(\"div\", {'class':'rating reviewItemInline'}):\n",
    "        sp = str(sp.find(\"span\")['class'][1])[7]\n",
    "        rating.append(sp)\n",
    "\n",
    "    for uinfo in soup.find_all(\"div\", {'class':'username mo'}):\n",
    "        name.append(uinfo.getText())\n",
    "\n",
    "    for rv in soup.find_all(\"p\", {'class':'partial_entry'}): \n",
    "        review.append(rv.getText())\n",
    "\n",
    "    for tt in soup.find_all(\"span\", {'class':'noQuotes'}):\n",
    "        title.append(tt.getText())\n",
    "\n",
    "    for rvdt in soup.find_all(\"span\", {'class':'ratingDate relativeDate'}):\n",
    "        review_date.append(rvdt['title']) \n",
    "\n",
    "    page_number = int(soup.find('span', class_=\"pageNum current\")['data-page-number'])\n",
    "\n",
    "    data['title'] = title\n",
    "    data['review'] = review\n",
    "    data['review_date'] = review_date\n",
    "    data['rating'] = rating\n",
    "    data['name'] = name\n",
    "    \n",
    "\n",
    "    all_data.update(data)  \n",
    "    all_data['review'] = [s.strip('\\n') for s in all_data['review']]\n",
    "    all_data['name'] = [s.strip('\\n') for s in all_data['name']]\n",
    "    \n",
    "    print(page_num)\n",
    "    page_num += 1\n",
    "    \n",
    "    next_page = soup.find('link', rel=\"next\")\n",
    "    if next_page:\n",
    "        next_page_url = next_page['href']\n",
    "        \n",
    "    next_url = 'http://www.tripadvisor.com' + next_page_url    \n",
    "    \n",
    "    if next_page:\n",
    "        url = 'http://www.tripadvisor.com' + next_page_url\n",
    "    else:\n",
    "        ret = 0\n",
    "\n",
    "review_df = pd.DataFrame.from_dict(all_data, orient='index')\n",
    "review_df = review_df.transpose()\n",
    "review_df = review_df[['review_date','name','rating','title','review']]\n",
    "review_df.to_excel('Embassy_Suites.xlsx')      \n",
    "       \n",
    "print(\"---took %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Data Imported\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
