{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyzomato import Pyzomato\n",
    "# b09d2806a00d1b4a0d798b4f5b5e5206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/flyankur/Zomato-API-python-wrapper/blob/master/zomato.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': [{'categories': {'id': 1, 'name': 'Delivery'}},\n",
       "  {'categories': {'id': 2, 'name': 'Dine-out'}},\n",
       "  {'categories': {'id': 3, 'name': 'Nightlife'}},\n",
       "  {'categories': {'id': 4, 'name': 'Catching-up'}},\n",
       "  {'categories': {'id': 5, 'name': 'Takeaway'}},\n",
       "  {'categories': {'id': 6, 'name': 'Cafes'}},\n",
       "  {'categories': {'id': 7, 'name': 'Daily Menus'}},\n",
       "  {'categories': {'id': 8, 'name': 'Breakfast'}},\n",
       "  {'categories': {'id': 9, 'name': 'Lunch'}},\n",
       "  {'categories': {'id': 10, 'name': 'Dinner'}},\n",
       "  {'categories': {'id': 11, 'name': 'Pubs & Bars'}},\n",
       "  {'categories': {'id': 13, 'name': 'Pocket Friendly Delivery'}},\n",
       "  {'categories': {'id': 14, 'name': 'Clubs & Lounges'}}]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YOUR_API_KEY = 'b09d2806a00d1b4a0d798b4f5b5e5206'\n",
    "p = Pyzomato(YOUR_API_KEY)\n",
    "p.search(q=\"Bangalore\")\n",
    "\n",
    "p.getCategories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zomato Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from lxml import html,etree\n",
    "import os,sys\n",
    "import urllib\n",
    "import time as tm\n",
    "from selenium import webdriver\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resturant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.zomato.com/bangalore'\n",
    "# html = urllib.request.urlopen(url)\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver.find_element_by_link_text('Log in').click()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//*[@id=\"login-email\"]').click() \n",
    "\n",
    "usernam = \"jitsubhra492@gmail.com\"\n",
    "passwor = \"\"\n",
    "\n",
    "username = driver.find_element_by_id('ld-email')\n",
    "password = driver.find_element_by_id('ld-password')\n",
    "\n",
    "username.send_keys(usernam)\n",
    "password.send_keys(passwor)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"ld-submit-global\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = []\n",
    "for s in soup.find_all(\"div\", {'class': 'ui segment eight column doubling padded grid'}):\n",
    "    for a in s.find_all(\"a\",{'class': 'column ta-center start-categories-item'}):\n",
    "        values.append(a['href']) \n",
    "keys = []\n",
    "for typ in values:\n",
    "    keys.append(typ.split('/')[-1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_rest = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = type_rest['drinks-and-nightlife']\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rest_area = []\n",
    "for s in soup.find_all(\"div\", {'class': 'additional-options mt0 ui segment'}):\n",
    "    for se in s.find_all(\"div\", {'class': 'w75 left nowrap'}):\n",
    "        rest_area.append(se.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zo = 'https://www.zomato.com'\n",
    "res_area_link = []\n",
    "for s in soup.find_all(\"div\", {'class': 'additional-options mt0 ui segment'}):\n",
    "    for res in rest_area:\n",
    "        for a in s.find_all(\"a\",{'title': 'Restaurants in ' + res}):\n",
    "            res_area_link.append(zo + a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.zomato.com/bangalore/drinks-and-nightlife-in-indiranagar'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_info = dict(zip(rest_area, res_area_link))\n",
    "rest_info['Indiranagar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = rest_info['Indiranagar']\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_name_temp = []\n",
    "res_link = []\n",
    "for s in soup.find_all(\"div\", {'class': 'content'}):\n",
    "    for a in s.find_all(\"div\", {'class': 'js-search-result-li even status 1'}):\n",
    "        for b in a.find_all(\"div\", {'class': 'row'}):\n",
    "            for c in b.find_all(\"a\",{'class':'result-title hover_feedback zred bold ln24 fontsize0 '}):\n",
    "                res_link.append(c['href'])\n",
    "                res_name_temp.append(c.getText().split('\\n'[0]))\n",
    "res_name = []\n",
    "for res in res_name_temp:\n",
    "    res_name.append(res[0])   \n",
    "\n",
    "indr_rest_info = dict(zip(res_name, res_link))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver1 = webdriver.Chrome('chromedriver.exe')\n",
    "url = 'https://www.zomato.com/bangalore/612-east-indiranagar' \n",
    "driver1.get(url)\n",
    "time.sleep(10)\n",
    "# locators = [\n",
    "#     (By.XPATH, '//*[@id=\"selectors\"]/a[2]'),    \n",
    "#     ]\n",
    "# for by, value in locators:\n",
    "#     try:\n",
    "#         driver1.find_element(by, value).click()\n",
    "#     except:\n",
    "#         driver1.find_element(by, value).click()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver1.find_element_by_xpath('//*[@id=\"selectors\"]/a[2]').click()\n",
    "        \n",
    "html = driver1.page_source\n",
    "soup = BeautifulSoup(html,'lxml') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = []\n",
    "for s in soup.find_all('div',{'id':'selectors'}):\n",
    "    for a in s.find_all('span',{'class':'grey-text'}):\n",
    "        count.append(a.getText())\n",
    "count = count[1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ret = 1\n",
    "while ret < int(count)//5:\n",
    "    locators = [\n",
    "    (By.XPATH, '//*[@id=\"reviews-container\"]/div[1]/div[3]/div/div/div[2]/div[1]/span[1]'),    \n",
    "    ]\n",
    "    for by, value in locators:\n",
    "        try:\n",
    "            driver1.find_element(by, value).click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            ret = int(count)//5 \n",
    "#     print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expand = driver1.find_elements_by_class_name('rev-text-expand ')\n",
    "for ex in expand:\n",
    "    driver1.execute_script(\"arguments[0].click()\", ex) \n",
    "    \n",
    "for mgr in soup.find_all(\"div\", {'class':'review-reply-text zblack content '}): \n",
    "        mgr.decompose()\n",
    "for mgr in soup.find_all(\"div\", {'class':'metadata'}): \n",
    "        mgr.decompose()        \n",
    "html = driver1.page_source\n",
    "soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datetime = []\n",
    "day = []\n",
    "rating = []\n",
    "reviews = []\n",
    "tt = []\n",
    "text=re.compile(r'rev-text mbot0 ')\n",
    "for s in soup.find_all('div',{'class':' ui segments res-review-body res-review clearfix js-activity-root mbti item-to-hide-parent stupendousact'}):\n",
    "    for s1 in s.find_all('div',{'class':'fs12px pbot0 clearfix'}):\n",
    "        for s2 in s1.find_all('a',{'class':'grey-text'}):\n",
    "            datetime.append(s2.time['datetime'])\n",
    "            day.append(s2.getText().replace('\\n',''))\n",
    "    for r in s.find_all('div',{'class':text}):\n",
    "        rating.append(r.div['aria-label'].split(' ')[1])\n",
    "        tt.append(r.getText().split('\\n'))   \n",
    "\n",
    "for t in tt:\n",
    "    reviews.append([item for item in t if item != ''][1].strip())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-09-22 14:15:17</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>Beautiful place.  Perfect for a lazy afternoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-09-21 13:45:10</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>We had a party for 35 odd ppl, took a package ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-20 20:55:32</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>Nice place. Great food and service. Value for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-09-20 15:10:56</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Liked the food and the ambience. But was disap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-09-20 00:00:11</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Food is good 💚nice 🍻🍸🍷place to hangout make it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-09-18 11:41:49</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>We had a really nice experience at 612East. Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-09-18 11:36:37</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>Have heard a lot about this place so decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-09-18 10:57:45</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>Great food and ambiance but the cocktails need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-09-18 10:03:36</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>612 East is the newest party place in the busy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-18 01:05:55</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>A new place in indiranagar. Visited this place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-09-17 16:57:19</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>The place is nice and the best part is their p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-09-17 15:22:46</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>This place was recently opened so thought of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-17 13:35:34</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Last Sunday we were in a situation where it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-09-17 10:15:49</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Had the beef steak,  twice slow cooked pork be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-15 10:34:54</td>\n",
       "      <td>7 days ago</td>\n",
       "      <td>This is one place where you get outstanding st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-11 23:03:31</td>\n",
       "      <td>11 days ago</td>\n",
       "      <td>Lovely rooftop 'smokey' restaurant. This joint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-09-11 18:33:11</td>\n",
       "      <td>11 days ago</td>\n",
       "      <td>Have now been to 612East two times and have en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-10 23:57:39</td>\n",
       "      <td>12 days ago</td>\n",
       "      <td>Loved each and every food of it.d cocktails .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-09-10 12:42:37</td>\n",
       "      <td>12 days ago</td>\n",
       "      <td>We Had been to this place for dinner with offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-09-09 21:36:18</td>\n",
       "      <td>13 days ago</td>\n",
       "      <td>In the lane of Fatty bao, above Entertainment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-09-09 19:44:58</td>\n",
       "      <td>13 days ago</td>\n",
       "      <td>The food is amazing, though the options for ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-09-09 18:52:07</td>\n",
       "      <td>13 days ago</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-09 12:22:23</td>\n",
       "      <td>13 days ago</td>\n",
       "      <td>612 East, what a beauty of a place. They've do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-09-09 11:50:07</td>\n",
       "      <td>13 days ago</td>\n",
       "      <td>Great food!  The rooftop is the perfect place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-09-09 09:32:51</td>\n",
       "      <td>13 days ago</td>\n",
       "      <td>Going out for a drink on Friday's is a ritual ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2017-09-08 16:10:06</td>\n",
       "      <td>14 days ago</td>\n",
       "      <td>Very very average food taste.... Oily items......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-09-08 00:51:24</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>I am a regular at a few places and quite skept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-09-07 22:53:01</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>Visited this place yesterday! The service was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-09-07 22:17:28</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>The creamy caujun pasta is just amazing can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-06 17:15:41</td>\n",
       "      <td>16 days ago</td>\n",
       "      <td>This place has a very good vibe. Look and feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-07-09 23:24:31</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>A spacious Place for Weekend nights with great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-07-09 16:08:30</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>We were there on Friday, really liked the plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-09 02:39:22</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Boom 💥!!! Exactly that kind of place which blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 23:46:07</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>This new place comes with three floors, person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-07-08 22:00:30</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Brilliant food, excellent cocktails . The serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 16:15:35</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>The most phenomenal place for great f &amp; b ! Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-07-08 15:58:01</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>The best spot in the town, i have tried many p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-07-08 15:39:37</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Another wonderful place to chill out and relax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 15:10:07</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>A very new and unique outlet which is located ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 14:45:04</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Another new place added to Indiranagar,  locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 13:42:43</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>To begin with, what a beautiful vibe this plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 13:31:25</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>In love with the rooftop! 😍😍😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-07-08 12:18:36</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Yet another place on the busy and crowded neig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-07-08 11:41:35</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Had been there on friday night,place is awesom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 11:26:24</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>What a vibe this place has!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 11:14:58</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Awesome place to visit , nice ambience the roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 11:11:18</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>I love the place love the ambience especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 08:54:08</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>The food is excellent we had a half and half p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2017-07-08 02:03:44</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Located on 12th Main, Indiranagar, 612 East ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-07-08 00:52:06</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Excellent place to be at . It's located at a v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-07-08 00:09:18</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Food is good.. but the service is very poor. F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-08 00:08:50</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Super place super food super cocktails and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-07 23:57:22</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>3 floors of blissful experiences! F &amp; b , the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-07 22:36:00</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Absolutely beautiful!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-07-07 22:22:21</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Poorly managed place. A/c didn't seem to work....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-07 19:33:42</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Brilliant vibe! Excellent food! Great music! F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-07 17:35:01</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>When you have a breathtaking space spread acro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-07 14:55:10</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Went to 612 East yesterday night. For someone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-07 12:14:47</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>What an amazing place with the best vibe Indir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-07 11:13:18</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>I can see this place becoming Indiranagar's fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                    1             2  \\\n",
       "0    4.5  2017-09-22 14:15:17   3 hours ago   \n",
       "1    2.0  2017-09-21 13:45:10     yesterday   \n",
       "2    4.0  2017-09-20 20:55:32     yesterday   \n",
       "3    3.5  2017-09-20 15:10:56    2 days ago   \n",
       "4    3.0  2017-09-20 00:00:11    3 days ago   \n",
       "5    5.0  2017-09-18 11:41:49    4 days ago   \n",
       "6    3.0  2017-09-18 11:36:37    4 days ago   \n",
       "7    3.5  2017-09-18 10:57:45    4 days ago   \n",
       "8    4.5  2017-09-18 10:03:36    4 days ago   \n",
       "9    4.0  2017-09-18 01:05:55    5 days ago   \n",
       "10   3.5  2017-09-17 16:57:19    5 days ago   \n",
       "11   3.0  2017-09-17 15:22:46    5 days ago   \n",
       "12   4.0  2017-09-17 13:35:34    5 days ago   \n",
       "13   5.0  2017-09-17 10:15:49    5 days ago   \n",
       "14   4.0  2017-09-15 10:34:54    7 days ago   \n",
       "15   4.0  2017-09-11 23:03:31   11 days ago   \n",
       "16   4.5  2017-09-11 18:33:11   11 days ago   \n",
       "17   4.0  2017-09-10 23:57:39   12 days ago   \n",
       "18   1.0  2017-09-10 12:42:37   12 days ago   \n",
       "19   3.5  2017-09-09 21:36:18   13 days ago   \n",
       "20   4.5  2017-09-09 19:44:58   13 days ago   \n",
       "21   1.0  2017-09-09 18:52:07   13 days ago   \n",
       "22   4.0  2017-09-09 12:22:23   13 days ago   \n",
       "23   5.0  2017-09-09 11:50:07   13 days ago   \n",
       "24   3.0  2017-09-09 09:32:51   13 days ago   \n",
       "25   1.5  2017-09-08 16:10:06   14 days ago   \n",
       "26   5.0  2017-09-08 00:51:24   15 days ago   \n",
       "27   3.0  2017-09-07 22:53:01   15 days ago   \n",
       "28   5.0  2017-09-07 22:17:28   15 days ago   \n",
       "29   4.0  2017-09-06 17:15:41   16 days ago   \n",
       "..   ...                  ...           ...   \n",
       "192  4.5  2017-07-09 23:24:31  2 months ago   \n",
       "193  4.5  2017-07-09 16:08:30  2 months ago   \n",
       "194  5.0  2017-07-09 02:39:22  2 months ago   \n",
       "195  5.0  2017-07-08 23:46:07  2 months ago   \n",
       "196  4.0  2017-07-08 22:00:30  2 months ago   \n",
       "197  5.0  2017-07-08 16:15:35  2 months ago   \n",
       "198  4.5  2017-07-08 15:58:01  2 months ago   \n",
       "199  4.0  2017-07-08 15:39:37  2 months ago   \n",
       "200  5.0  2017-07-08 15:10:07  2 months ago   \n",
       "201  5.0  2017-07-08 14:45:04  2 months ago   \n",
       "202  5.0  2017-07-08 13:42:43  2 months ago   \n",
       "203  5.0  2017-07-08 13:31:25  2 months ago   \n",
       "204  4.0  2017-07-08 12:18:36  2 months ago   \n",
       "205  4.5  2017-07-08 11:41:35  2 months ago   \n",
       "206  5.0  2017-07-08 11:26:24  2 months ago   \n",
       "207  5.0  2017-07-08 11:14:58  2 months ago   \n",
       "208  5.0  2017-07-08 11:11:18  2 months ago   \n",
       "209  5.0  2017-07-08 08:54:08  2 months ago   \n",
       "210  1.5  2017-07-08 02:03:44  2 months ago   \n",
       "211  4.5  2017-07-08 00:52:06  2 months ago   \n",
       "212  3.0  2017-07-08 00:09:18  2 months ago   \n",
       "213  5.0  2017-07-08 00:08:50  2 months ago   \n",
       "214  5.0  2017-07-07 23:57:22  2 months ago   \n",
       "215  5.0  2017-07-07 22:36:00  2 months ago   \n",
       "216  1.0  2017-07-07 22:22:21  2 months ago   \n",
       "217  5.0  2017-07-07 19:33:42  2 months ago   \n",
       "218  5.0  2017-07-07 17:35:01  2 months ago   \n",
       "219  5.0  2017-07-07 14:55:10  2 months ago   \n",
       "220  5.0  2017-07-07 12:14:47  2 months ago   \n",
       "221  5.0  2017-07-07 11:13:18  2 months ago   \n",
       "\n",
       "                                                     3  \n",
       "0    Beautiful place.  Perfect for a lazy afternoon...  \n",
       "1    We had a party for 35 odd ppl, took a package ...  \n",
       "2    Nice place. Great food and service. Value for ...  \n",
       "3    Liked the food and the ambience. But was disap...  \n",
       "4    Food is good 💚nice 🍻🍸🍷place to hangout make it...  \n",
       "5    We had a really nice experience at 612East. Me...  \n",
       "6    Have heard a lot about this place so decided t...  \n",
       "7    Great food and ambiance but the cocktails need...  \n",
       "8    612 East is the newest party place in the busy...  \n",
       "9    A new place in indiranagar. Visited this place...  \n",
       "10   The place is nice and the best part is their p...  \n",
       "11   This place was recently opened so thought of t...  \n",
       "12   Last Sunday we were in a situation where it wa...  \n",
       "13   Had the beef steak,  twice slow cooked pork be...  \n",
       "14   This is one place where you get outstanding st...  \n",
       "15   Lovely rooftop 'smokey' restaurant. This joint...  \n",
       "16   Have now been to 612East two times and have en...  \n",
       "17   Loved each and every food of it.d cocktails .....  \n",
       "18   We Had been to this place for dinner with offi...  \n",
       "19   In the lane of Fatty bao, above Entertainment ...  \n",
       "20   The food is amazing, though the options for ve...  \n",
       "21                                                      \n",
       "22   612 East, what a beauty of a place. They've do...  \n",
       "23   Great food!  The rooftop is the perfect place ...  \n",
       "24   Going out for a drink on Friday's is a ritual ...  \n",
       "25   Very very average food taste.... Oily items......  \n",
       "26   I am a regular at a few places and quite skept...  \n",
       "27   Visited this place yesterday! The service was ...  \n",
       "28   The creamy caujun pasta is just amazing can't ...  \n",
       "29   This place has a very good vibe. Look and feel...  \n",
       "..                                                 ...  \n",
       "192  A spacious Place for Weekend nights with great...  \n",
       "193  We were there on Friday, really liked the plac...  \n",
       "194  Boom 💥!!! Exactly that kind of place which blo...  \n",
       "195  This new place comes with three floors, person...  \n",
       "196  Brilliant food, excellent cocktails . The serv...  \n",
       "197  The most phenomenal place for great f & b ! Am...  \n",
       "198  The best spot in the town, i have tried many p...  \n",
       "199  Another wonderful place to chill out and relax...  \n",
       "200  A very new and unique outlet which is located ...  \n",
       "201  Another new place added to Indiranagar,  locat...  \n",
       "202  To begin with, what a beautiful vibe this plac...  \n",
       "203                      In love with the rooftop! 😍😍😍  \n",
       "204  Yet another place on the busy and crowded neig...  \n",
       "205  Had been there on friday night,place is awesom...  \n",
       "206                      What a vibe this place has!!!  \n",
       "207  Awesome place to visit , nice ambience the roo...  \n",
       "208  I love the place love the ambience especially ...  \n",
       "209  The food is excellent we had a half and half p...  \n",
       "210  Located on 12th Main, Indiranagar, 612 East ha...  \n",
       "211  Excellent place to be at . It's located at a v...  \n",
       "212  Food is good.. but the service is very poor. F...  \n",
       "213  Super place super food super cocktails and the...  \n",
       "214  3 floors of blissful experiences! F & b , the ...  \n",
       "215                             Absolutely beautiful!!  \n",
       "216  Poorly managed place. A/c didn't seem to work....  \n",
       "217  Brilliant vibe! Excellent food! Great music! F...  \n",
       "218  When you have a breathtaking space spread acro...  \n",
       "219  Went to 612 East yesterday night. For someone ...  \n",
       "220  What an amazing place with the best vibe Indir...  \n",
       "221  I can see this place becoming Indiranagar's fa...  \n",
       "\n",
       "[222 rows x 4 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(rating, datetime,day, reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indiranagar all resturant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from lxml import html,etree\n",
    "import os,sys\n",
    "import urllib\n",
    "import time as tm\n",
    "from selenium import webdriver\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.zomato.com/bangalore'\n",
    "# html = urllib.request.urlopen(url)\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.zomato.com/bangalore/drinks-and-nightlife-in-indiranagar'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zomato = 'https://www.zomato.com'\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "keys = []\n",
    "values = []\n",
    "rest_area = []\n",
    "res_area_link = []\n",
    "\n",
    "for s in soup.find_all(\"div\", {'class': 'ui segment eight column doubling padded grid'}):\n",
    "    for a in s.find_all(\"a\",{'class': 'column ta-center start-categories-item'}):\n",
    "        values.append(a['href']) \n",
    "\n",
    "for typ in values:\n",
    "    keys.append(typ.split('/')[-1]) \n",
    "    \n",
    "type_rest = dict(zip(keys, values))\n",
    "\n",
    "url = type_rest['drinks-and-nightlife']\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "for s in soup.find_all(\"div\", {'class': 'additional-options mt0 ui segment'}):\n",
    "    for se in s.find_all(\"div\", {'class': 'w75 left nowrap'}):\n",
    "        rest_area.append(se.getText())\n",
    "\n",
    "for s in soup.find_all(\"div\", {'class': 'additional-options mt0 ui segment'}):\n",
    "    for res in rest_area:\n",
    "        for a in s.find_all(\"a\",{'title': 'Restaurants in ' + res}):\n",
    "            res_area_link.append(zomato + a['href'])  \n",
    "            \n",
    "rest_info = dict(zip(rest_area, res_area_link))\n",
    "rest_info['Indiranagar']            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.zomato.com/bangalore/drinks-and-nightlife-in-indiranagar\n",
      "https://www.zomato.com/bangalore/drinks-and-nightlife-in-indiranagar?page=2\n",
      "https://www.zomato.com/bangalore/drinks-and-nightlife-in-indiranagar?page=3\n",
      "https://www.zomato.com/bangalore/drinks-and-nightlife-in-indiranagar?page=4\n",
      "https://www.zomato.com/bangalore/drinks-and-nightlife-in-indiranagar?page=5\n"
     ]
    }
   ],
   "source": [
    "zomato = 'https://www.zomato.com'\n",
    "\n",
    "url = rest_info['Indiranagar']\n",
    "res_name_temp = []\n",
    "res_link = []\n",
    "res_name = []\n",
    "res_id = []\n",
    "ret = 1\n",
    "text = re.compile(r'rating-popup rating-for-.*')\n",
    "rest_rating = []\n",
    "column = ['resturant','rest_id', 'rest_link','rest_rating']\n",
    "\n",
    "while ret:\n",
    "    print(url)\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    for c in soup.find_all('a',{'class':'result-title hover_feedback zred bold ln24 fontsize0 '}):\n",
    "        res_name_temp.append(c.getText().split('\\n'[0][0]))\n",
    "        res_link.append(c['href']) \n",
    "     \n",
    "    \n",
    "    for c in soup.find_all('div',{'class':text}):\n",
    "        rest_rating.append(c.getText().strip())\n",
    "    \n",
    "    next_page = soup.find('a',{'class':'paginator_item next item'})\n",
    "    \n",
    "    if next_page:\n",
    "        url = zomato + next_page['href']\n",
    "    else:\n",
    "        ret = 0\n",
    "\n",
    "for r in res_name_temp:\n",
    "    res_name.append(r[0]) \n",
    "\n",
    "for r in res_name:\n",
    "    res_id.append(r + '_' + str(uuid.uuid1()))\n",
    "    \n",
    "indr_rest_info = dict(zip(res_name, res_link)) \n",
    "indr_rest_id = dict(zip(res_name, res_id))\n",
    "df = pd.DataFrame(list(zip(res_name,res_id, res_link,rest_rating)),columns=column)\n",
    "df.to_excel('./resturants/all_resturant/zomato_resturants_master.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews all hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# url = indr_rest_info['Toit']\n",
    "# df = pd.DataFrame()\n",
    "column = ['resturant','rating','datetime','day','reviews']\n",
    "for res,url in indr_rest_info1.items():\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"selectors\"]/a[2]').click()\n",
    "    except:\n",
    "        driver.find_element_by_xpath('//*[@id=\"selectors\"]/a[2]/span').click()\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'lxml') \n",
    "\n",
    "    count = []\n",
    "    for s in soup.find_all('div',{'id':'selectors'}):\n",
    "        for a in s.find_all('span',{'class':'grey-text'}):\n",
    "            count.append(a.getText())\n",
    "#     print(count)\n",
    "    count = count[1] \n",
    "    print('resturant name : ',res)\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "    ret = 1\n",
    "    while ret < int(count)//5:\n",
    "        \n",
    "#         if(ret <= 2000):\n",
    "        locators = [\n",
    "        (By.XPATH, '//*[@id=\"reviews-container\"]/div[1]/div[3]/div/div/div[2]/div[1]/span[1]'),   \n",
    "        ]\n",
    "        for by, value in locators:\n",
    "            try:\n",
    "                driver.find_element(by, value).click()\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                ret = int(count)//5 \n",
    "#                 print(ret)\n",
    "#             ret = ret + 1\n",
    "#         else:\n",
    "#             ret = int(count)//5\n",
    "\n",
    "    expand = driver.find_elements_by_class_name('rev-text-expand ')\n",
    "    for ex in expand:\n",
    "        driver.execute_script(\"arguments[0].click()\", ex) \n",
    "\n",
    "    for mgr in soup.find_all(\"div\", {'class':'review-reply-text zblack content '}): \n",
    "            mgr.decompose()\n",
    "    for mgr in soup.find_all(\"div\", {'class':'metadata'}): \n",
    "            mgr.decompose()        \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'lxml')   \n",
    "\n",
    "    datetime = []\n",
    "    day = []\n",
    "    rating = []\n",
    "    reviews = []\n",
    "    rest = []\n",
    "    tt = []\n",
    "    text=re.compile(r'rev-text mbot0 ')\n",
    "    for s in soup.find_all('div',{'class':' ui segments res-review-body res-review clearfix js-activity-root mbti item-to-hide-parent stupendousact'}):\n",
    "        for s1 in s.find_all('div',{'class':'fs12px pbot0 clearfix'}):\n",
    "            for s2 in s1.find_all('a',{'class':'grey-text'}):\n",
    "                datetime.append(s2.time['datetime'])\n",
    "                day.append(s2.getText().replace('\\n',''))\n",
    "        for r in s.find_all('div',{'class':text}):\n",
    "            rating.append(r.div['aria-label'].split(' ')[1])\n",
    "            tt.append(r.getText().split('\\n'))   \n",
    "\n",
    "    for t in tt:\n",
    "        reviews.append([item for item in t if item != ''][1].strip())\n",
    "    \n",
    "    for r in range(len(reviews)):\n",
    "        rest.append(res)\n",
    "    \n",
    "    df1 = pd.DataFrame(list(zip(rest,rating, datetime,day, reviews)),columns=column) \n",
    "    df1.to_excel('./resturants/%s_resturant_data.xlsx' % res,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = list(indr_rest_info.keys())[62:]\n",
    "y = list(indr_rest_info.values())[62:]\n",
    "indr_rest_info1 = dict(zip(x, y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "path =r'D:\\Users\\us54674\\OneDrive - Grant Thornton LLP\\python\\WebScraping\\resturants' # use your path\n",
    "allFiles = glob.glob(path + \"/*.xlsx\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_excel(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_)\n",
    "\n",
    "frame.to_excel('./resturants/all_resturant/zomato_resturants.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalsentiment(hotel):\n",
    "    length = len(hotel)\n",
    "    trans = []\n",
    "    for i in range(length):\n",
    "        data = TextBlob(hotel[\"reviews\"][i])\n",
    "        if data.detect_language() == \"en\":\n",
    "            trans.append(data)\n",
    "            continue\n",
    "        else:\n",
    "            trans.append(data.translate(to='en'))   \n",
    "    return trans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The `text` argument passed to `__init__(text)` must be a string, not <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-1cea2564ddb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membassy_suits_sentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membassy_suits_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalsentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membassy_suits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0membassy_suits_pol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0membassy_suits_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-93d389517f58>\u001b[0m in \u001b[0;36mnormalsentiment\u001b[0;34m(hotel)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhotel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"reviews\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"en\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, tokenizer, pos_tagger, np_extractor, analyzer, parser, classifier, clean_html)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             raise TypeError('The `text` argument passed to `__init__(text)` '\n\u001b[0;32m--> 361\u001b[0;31m                             'must be a string, not {0}'.format(type(text)))\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclean_html\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             raise NotImplementedError(\"clean_html has been deprecated. \"\n",
      "\u001b[0;31mTypeError\u001b[0m: The `text` argument passed to `__init__(text)` must be a string, not <class 'float'>"
     ]
    }
   ],
   "source": [
    "embassy_suits = pd.read_excel(\"./resturants/all_resturant/zomato_resturants.xlsx\")\n",
    "\n",
    "embassy_suits_sentiment = []\n",
    "embassy_suits_trans = normalsentiment(embassy_suits) \n",
    "embassy_suits_pol = []\n",
    "embassy_suits_sub = []\n",
    "\n",
    "\n",
    "for text in embassy_suits_trans:\n",
    "        embassy_suits_sentiment.append(text.sentiment)\n",
    "        \n",
    "len_embassy_suits_sentiment = len(embassy_suits_sentiment)        \n",
    "        \n",
    "for nor in range(len_embassy_suits_sentiment):\n",
    "    embassy_suits_pol.append(embassy_suits_sentiment[nor].polarity)\n",
    "    embassy_suits_sub.append(embassy_suits_sentiment[nor].subjectivity)\n",
    "\n",
    "embassy_suits.to_excel(\"./resturants/all_resturant/hotel_sentiments.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "trans = []\n",
    "length = len(embassy_suits)\n",
    "for i in range(length):\n",
    "    print(i)\n",
    "    embassy_suits[\"reviews\"][i] = str([cell.encode('utf-8') for cell in embassy_suits[\"reviews\"][i]])\n",
    "    data = TextBlob(embassy_suits[\"reviews\"][i])\n",
    "    if data.detect_language() == \"en\":\n",
    "        trans.append(data)\n",
    "        continue\n",
    "    else:\n",
    "        trans.append(data.translate(to='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
