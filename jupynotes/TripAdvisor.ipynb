{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraper Inititated for Locality:boston\n",
      "Finding search result page URL\n",
      "URL found http://www.tripadvisor.com/Hotels-g60745-Boston_Massachusetts-Hotels.html\n",
      "Downloading search results page\n",
      "Parsing results \n",
      "Writing to output file tripadvisor_data.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from time import time\n",
    "from lxml import html,etree\n",
    "import requests,re\n",
    "import os,sys\n",
    "import unicodecsv as csv\n",
    "import argparse\n",
    "\n",
    "def parse(locality,checkin_date,checkout_date,sort):\n",
    "    checkIn = checkin_date.strftime(\"%Y/%m/%d\")\n",
    "    checkOut = checkout_date.strftime(\"%Y/%m/%d\")\n",
    "    print \"Scraper Inititated for Locality:%s\"%locality\n",
    "    # TA rendering the autocomplete list using this API\n",
    "    print \"Finding search result page URL\"\n",
    "    geo_url = 'https://www.tripadvisor.com/TypeAheadJson?action=API&startTime='+str(int(time()))+'&uiOrigin=GEOSCOPE&source=GEOSCOPE&interleaved=true&types=geo,theme_park&neighborhood_geos=true&link_type=hotel&details=true&max=12&injectNeighborhoods=true&query='+locality\n",
    "    api_response  = requests.get(geo_url).json()\n",
    "    #getting the TA url for th equery from the autocomplete response\n",
    "    url_from_autocomplete = \"http://www.tripadvisor.com\"+api_response['results'][0]['url']\n",
    "    print 'URL found %s'%url_from_autocomplete\n",
    "    geo = api_response['results'][0]['value']   \n",
    "    #Formating date for writing to file \n",
    "    \n",
    "    date = checkin_date.strftime(\"%Y_%m_%d\")+\"_\"+checkout_date.strftime(\"%Y_%m_%d\")\n",
    "    #form data to get the hotels list from TA for the selected date\n",
    "    form_data ={\n",
    "                    'adults': '2',\n",
    "                    'dateBumped': 'NONE',\n",
    "                    'displayedSortOrder':sort,\n",
    "                    'geo': geo,\n",
    "                    'hs': '',\n",
    "                    'isFirstPageLoad': 'false',\n",
    "                    'rad': '0',\n",
    "                    'refineForm': 'true',\n",
    "                    'requestingServlet': 'Hotels',\n",
    "                    'rooms': '1',\n",
    "                    'scid': 'null_coupon',\n",
    "                    'searchAll': 'false',\n",
    "                    'seen': '0',\n",
    "                    'sequence': '7',\n",
    "                    'o':\"0\",\n",
    "                    'staydates': date\n",
    "    }\n",
    "    #Referrer is necessary to get the correct response from TA if not provided they will redirect to home page\n",
    "    headers = {\n",
    "                            'Accept': 'text/javascript, text/html, application/xml, text/xml, */*',\n",
    "                            'Accept-Encoding': 'gzip,deflate',\n",
    "                            'Accept-Language': 'en-US,en;q=0.5',\n",
    "                            'Cache-Control': 'no-cache',\n",
    "                            'Connection': 'keep-alive',\n",
    "                            'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8',\n",
    "                            'Host': 'www.tripadvisor.com',\n",
    "                            'Pragma': 'no-cache',\n",
    "                            'Referer': url_from_autocomplete,\n",
    "                            'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:28.0) Gecko/20100101 Firefox/28.0',\n",
    "                            'X-Requested-With': 'XMLHttpRequest'\n",
    "                        }\n",
    "    print \"Downloading search results page\"\n",
    "    page_response  = requests.post(url = \"https://www.tripadvisor.com/Hotels\",data=form_data,headers = headers).text\n",
    "    print \"Parsing results \"\n",
    "    parser = html.fromstring(page_response)\n",
    "    hotel_lists = parser.xpath('//div[contains(@class,\"meta_listing\")]')\n",
    "    hotel_data = []\n",
    "    for hotel in hotel_lists:\n",
    "        XPATH_HOTEL_LINK = './/div[@class=\"listing_title\"]/a/@href'\n",
    "        XPATH_REVIEWS  = './/span[@class=\"more review_count\"]//text()'\n",
    "        XPATH_RANK = './/div[@class=\"popRanking\"]//text()'\n",
    "        XPATH_RATING = './/div[@class=\"rating\"]//span[contains(@class,\"bubble_rating\")]/@alt'\n",
    "        XPATH_HOTEL_NAME = './/a[contains(@class,\"property_title\")]//text()'\n",
    "        XPATH_HOTEL_FEATURES = './/a[contains(@class,\"tag\")]/text()'\n",
    "        XPATH_HOTEL_PRICE = './/div[contains(@class,\"price\")]/text()'\n",
    "        XPATH_VIEW_DEALS = './/div[contains(@id,\"VIEW_ALL_DEALS\")]/span/text()' \n",
    "        XPATH_BOOKING_PROVIDER = './/div[contains(@class,\"providerLogo\")]/img/@alt'\n",
    "\n",
    "        raw_booking_provider = hotel.xpath(XPATH_BOOKING_PROVIDER)\n",
    "        raw_no_of_deals =  hotel.xpath(XPATH_VIEW_DEALS)\n",
    "        raw_hotel_link = hotel.xpath(XPATH_HOTEL_LINK)\n",
    "        raw_no_of_reviews = hotel.xpath(XPATH_REVIEWS)\n",
    "        raw_rank = hotel.xpath(XPATH_RANK)\n",
    "        raw_rating = hotel.xpath(XPATH_RATING)\n",
    "        raw_hotel_name = hotel.xpath(XPATH_HOTEL_NAME)\n",
    "        raw_hotel_features = hotel.xpath(XPATH_HOTEL_FEATURES)\n",
    "        raw_hotel_price_per_night  = hotel.xpath(XPATH_HOTEL_PRICE)\n",
    "\n",
    "        url = 'http://www.tripadvisor.com'+raw_hotel_link[0] if raw_hotel_link else  None\n",
    "        reviews = re.findall('(\\d+\\,?\\d+)',raw_no_of_reviews[0])[0].replace(',','') if raw_no_of_reviews else None\n",
    "        rank = ''.join(raw_rank) if raw_rank else None\n",
    "        rating = ''.join(raw_rating).replace(' of 5 bubbles','') if raw_rating else None\n",
    "        name = ''.join(raw_hotel_name).strip() if raw_hotel_name else None\n",
    "        hotel_features = ','.join(raw_hotel_features)\n",
    "        price_per_night = ''.join(raw_hotel_price_per_night).encode('utf-8').replace('\\n','') if raw_hotel_price_per_night else None\n",
    "        no_of_deals=  re.sub('\\D+','',''.join(raw_no_of_deals)) if raw_no_of_deals else None\n",
    "        # no_of_deals = re.sub('\\D+','',no_of_deals)\n",
    "        booking_provider = ''.join(raw_booking_provider).strip() if raw_booking_provider else None\n",
    "\n",
    "        data = {\n",
    "                    'hotel_name':name,\n",
    "                    'url':url,\n",
    "                    'locality':locality,\n",
    "                    'reviews':reviews,\n",
    "                    'tripadvisor_rating':rating,\n",
    "                    'checkOut':checkOut,\n",
    "                    'checkIn':checkIn,\n",
    "                    'hotel_features':hotel_features,\n",
    "                    'price_per_night':price_per_night,\n",
    "                    'no_of_deals':no_of_deals,\n",
    "                    'booking_provider':booking_provider\n",
    "\n",
    "        }\n",
    "        hotel_data.append(data)\n",
    "    return hotel_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('checkin_date',help = 'Hotel Check In Date (Format: YYYY/MM/DD')\n",
    "#     parser.add_argument('checkout_date',help = 'Hotel Chek Out Date (Format: YYYY/MM/DD)')\n",
    "#     sortorder_help = \"\"\"\n",
    "#     available sort orders are :\\n\n",
    "#     priceLow - hotels with lowest price,\n",
    "#     distLow : Hotels located near to the search center,\n",
    "#     recommended: highest rated hotels based on traveler reviews,\n",
    "#     popularity :Most popular hotels as chosen by Tipadvisor users \n",
    "#     \"\"\"\n",
    "#     parser.add_argument('sort',help = sortorder_help,default ='popularity ')\n",
    "#     parser.add_argument('locality',help = 'Search Locality')\n",
    "#     args = parser.parse_args()\n",
    "#     locality = args.locality\n",
    "#     checkin_date = datetime.strptime(args.checkin_date,\"%Y/%m/%d\")\n",
    "#     checkout_date = datetime.strptime(args.checkout_date,\"%Y/%m/%d\")\n",
    "#     sort= args.sort\n",
    "    locality = \"boston\"\n",
    "    checkin_date = datetime.strptime(\"2017/05/01\",\"%Y/%m/%d\")\n",
    "    checkout_date = datetime.strptime(\"2017/05/02\",\"%Y/%m/%d\")\n",
    "    sort= \"popularity\"\n",
    "    checkIn = checkin_date.strftime(\"%Y/%m/%d\")\n",
    "    checkOut = checkout_date.strftime(\"%Y/%m/%d\")\n",
    "    today = datetime.now()\n",
    "   \n",
    "    if today<datetime.strptime(checkIn,\"%Y/%m/%d\") and datetime.strptime(checkIn,\"%Y/%m/%d\")<datetime.strptime(checkOut,\"%Y/%m/%d\"):\n",
    "        data = parse(locality,checkin_date,checkout_date,sort)\n",
    "        print \"Writing to output file tripadvisor_data.csv\"\n",
    "        with open('tripadvisor_data.csv','w')as csvfile:\n",
    "            fieldnames = ['hotel_name','url','locality','reviews','tripadvisor_rating','checkIn','checkOut','price_per_night','booking_provider','no_of_deals','hotel_features']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for row in  data:\n",
    "                writer.writerow(row)\n",
    "    #checking whether the entered date is already passed\n",
    "    elif today>datetime.strptime(checkIn,\"%Y/%m/%d\") or today>datetime.strptime(checkOut,\"%Y/%m/%d\"):\n",
    "        print \"Invalid Checkin date: Please enter a valid checkin and checkout dates,entered date is already passed\"\n",
    "    \n",
    "    elif datetime.strptime(checkIn,\"%Y/%m/%d\")>datetime.strptime(checkOut,\"%Y/%m/%d\"):\n",
    "        print \"Invalid Checkin date: CheckIn date must be less than checkOut date\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://gist.github.com/scrapehero/ff1ddffb48c3bee89f5c7da4cf0c8786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching http://www.tripadvisor.ca/Hotel_Review-g190479-d3587956-Reviews-The_Thief-Oslo_Eastern_Norway.html#REVIEWS\n"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from collections import OrderedDict\n",
    "import pprint\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "def parse(url):\n",
    "    print \"Fetching \"+url\n",
    "    response = requests.get(url).text\n",
    "    parser = html.fromstring(response)\n",
    "    \n",
    "    XPATH_RATING = '//div[@id=\"ratingFilter\"]//ul//li'\n",
    "    XPATH_NAME = '//h1[@property=\"name\"]//text()'\n",
    "    XPATH_HOTEL_RATING = '//span[@property=\"ratingValue\"]//@content'\n",
    "    XPATH_REVIEWS = '//a[@property=\"reviewCount\"]/@content'\n",
    "    XPATH_RANK = '//div[contains(@class,\"popRanking\")]//text()'\n",
    "    XPATH_STREET_ADDRESS = \"//div[@class='header_container']//span[@class='street-address']//text()\"\n",
    "    XPATH_LOCALITY  = '//div[@class=\"header_container\"]//span[@property=\"addressLocality\"]//text()'\n",
    "    XPATH_ZIP = '//div[@class=\"header_container\"]//span[@property=\"postalCode\"]//text()'\n",
    "    XPATH_COUNTRY = '//div[@class=\"header_container\"]//span[@property=\"addressCountry\"]//@content'\n",
    "    XPATH_AMENITIES = '//div[@id=\"AMENITIES_TAB\"]//div[contains(@class,\"amenity_row\")]' \n",
    "    XPATH_HIGHLIGHTS = '//div[@class=\"property_tags_wrap\"]//li//text()'\n",
    "    XPATH_OFFICIAL_DESCRIPTION = '//div[contains(@class,\"additional_info\")]//span[contains(@class,\"tabs_descriptive_text\")]//text()'\n",
    "    XPATH_ADDITIONAL_INFO = '//div[@class=\"additional_info_amenities\"]//div[@class=\"content\"]//text()'\n",
    "    \n",
    "    ratings = parser.xpath(XPATH_RATING)\n",
    "    raw_name = parser.xpath(XPATH_NAME)\n",
    "    raw_rank = parser.xpath(XPATH_RANK)\n",
    "    raw_street_address = parser.xpath(XPATH_STREET_ADDRESS)\n",
    "    raw_locality = parser.xpath(XPATH_LOCALITY)\n",
    "    raw_zipcode =  parser.xpath(XPATH_ZIP)\n",
    "    raw_country = parser.xpath(XPATH_COUNTRY)\n",
    "    raw_review_count = parser.xpath(XPATH_REVIEWS)\n",
    "    raw_rating = parser.xpath(XPATH_HOTEL_RATING)\n",
    "    amenities = parser.xpath(XPATH_AMENITIES)\n",
    "    raw_highlights = parser.xpath(XPATH_HIGHLIGHTS)\n",
    "    raw_official_description = parser.xpath(XPATH_OFFICIAL_DESCRIPTION)\n",
    "    raw_additional_info = parser.xpath(XPATH_ADDITIONAL_INFO)\n",
    "\n",
    "                        \n",
    "    name = ''.join(raw_name).strip() if raw_name else None\n",
    "    rank = ''.join(raw_rank).strip() if raw_rank else None\n",
    "    street_address = ' '.join(raw_street_address).strip() if raw_street_address else None\n",
    "    locality = ' '.join(raw_locality).strip() if raw_locality else None\n",
    "    zipcode = ''.join(raw_zipcode).strip() if raw_zipcode else None\n",
    "    country  = ' '.join(raw_country).strip() if raw_country else None\n",
    "    review_count = ''.join(raw_review_count).strip() if raw_review_count else None\n",
    "    hotel_rating = ''.join(raw_rating).strip() if raw_rating else None\n",
    "    official_description = ' '.join(' '.join(raw_official_description).split()) if raw_official_description else None\n",
    "    additional_info = ' '.join(''.join(raw_additional_info).split()) if raw_additional_info else None\n",
    "    cleaned_highlights = filter(lambda x:x != '\\n', raw_highlights)\n",
    "    \n",
    "    highlights = ','.join(cleaned_highlights).replace('\\n','')\n",
    "    # Ordereddict is for preserve the site order\n",
    "    ratings_dict = OrderedDict()\n",
    "    for rating in ratings:\n",
    "        XPATH_RATING_KEY = './/div[@class=\"row_label\"]//text()'\n",
    "        XPATH_RATING_VALUE = './/span[@class=\"row_bar\"]/following-sibling::span//text()'\n",
    "\n",
    "        raw_rating_key = rating.xpath(XPATH_RATING_KEY)\n",
    "        raw_rating_value = rating.xpath(XPATH_RATING_VALUE)\n",
    "\n",
    "        cleaned_rating_key = ''.join(raw_rating_key).replace('\\n','')\n",
    "        cleaned_rating_value = ''.join(raw_rating_value).replace('\\n','')\n",
    "        ratings_dict.update({cleaned_rating_key:cleaned_rating_value})\n",
    "    \n",
    "\n",
    "    amenity_dict = OrderedDict()\n",
    "    for amenity in amenities:\n",
    "        XPATH_AMENITY_KEY = './/div[@class=\"amenity_hdr\"]//text()'\n",
    "        XPATH_AMENITY_VALUE = './/div[@class=\"amenity_lst\"]//li/text()'\n",
    "\n",
    "        raw_amenity_key = amenity.xpath(XPATH_AMENITY_KEY)\n",
    "        raw_amenity_value = amenity.xpath(XPATH_AMENITY_VALUE)\n",
    "        cleaned_aminity_value = filter(lambda x:x != ' ', raw_amenity_value)\n",
    "\n",
    "        amenity_key = ''.join(raw_amenity_key).replace('\\n','')\n",
    "        amenity_value = ' ,'.join(cleaned_aminity_value).replace('\\n','')\n",
    "        amenity_dict.update({amenity_key:amenity_value})\n",
    "    \n",
    "    address = {\n",
    "        'street_address':street_address,\n",
    "                    'locality':locality,\n",
    "                    'zipcode':zipcode,\n",
    "                    'country':country\n",
    "                }\n",
    "\n",
    "    data = {\n",
    "                'address':address,\n",
    "                'ratings':ratings_dict,\n",
    "                'amenities':amenity_dict,\n",
    "                'official_description':official_description,\n",
    "                'additional_info':additional_info,\n",
    "                'rating':hotel_rating,\n",
    "                'review_count':review_count,\n",
    "                'name':name,\n",
    "                'rank':rank,\n",
    "                'highlights':highlights\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__=='__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('url',help='Tripadvisor hotel url')\n",
    "#     args = parser.parse_args()\n",
    "#     url = args.url\n",
    "    url = \"http://www.tripadvisor.ca/Hotel_Review-g190479-d3587956-Reviews-The_Thief-Oslo_Eastern_Norway.html#REVIEWS\"\n",
    "    scraped_data = parse(url)\n",
    "    with open('tripadvisor_hotel_scraped_data.json','w') as f:\n",
    "        json.dump(scraped_data,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: http://www.amazon.in/dp/B01EKSSKXG\n",
      "Processing: http://www.amazon.in/dp/B00JGTVU5A\n",
      "Processing: http://www.amazon.in/dp/B00GJYCIVK\n",
      "Processing: http://www.amazon.in/dp/B00EPGK7CQ\n",
      "Processing: http://www.amazon.in/dp/B00EPGKA4G\n",
      "Processing: http://www.amazon.in/dp/B00YW5DLB4\n",
      "Processing: http://www.amazon.in/dp/B00KGD0628\n",
      "Processing: http://www.amazon.in/dp/B00O9A48N2\n",
      "Processing: http://www.amazon.in/dp/B00O9A4MEW\n",
      "Processing: http://www.amazon.in/dp/B00UZKG8QU\n"
     ]
    }
   ],
   "source": [
    "from lxml import html  \n",
    "import csv,os,json\n",
    "import requests\n",
    "from exceptions import ValueError\n",
    "from time import sleep\n",
    "\n",
    "def AmzonParser(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36'}\n",
    "    page = requests.get(url,headers=headers)\n",
    "    while True:\n",
    "        sleep(3)\n",
    "        try:\n",
    "            doc = html.fromstring(page.content)\n",
    "            XPATH_NAME = '//h1[@id=\"title\"]//text()'\n",
    "            XPATH_SALE_PRICE = '//span[contains(@id,\"ourprice\") or contains(@id,\"saleprice\")]/text()'\n",
    "            XPATH_ORIGINAL_PRICE = '//td[contains(text(),\"List Price\") or contains(text(),\"M.R.P\") or contains(text(),\"Price\")]/following-sibling::td/text()'\n",
    "            XPATH_CATEGORY = '//a[@class=\"a-link-normal a-color-tertiary\"]//text()'\n",
    "            XPATH_AVAILABILITY = '//div[@id=\"availability\"]//text()'\n",
    "\n",
    "            RAW_NAME = doc.xpath(XPATH_NAME)\n",
    "            RAW_SALE_PRICE = doc.xpath(XPATH_SALE_PRICE)\n",
    "            RAW_CATEGORY = doc.xpath(XPATH_CATEGORY)\n",
    "            RAW_ORIGINAL_PRICE = doc.xpath(XPATH_ORIGINAL_PRICE)\n",
    "            RAw_AVAILABILITY = doc.xpath(XPATH_AVAILABILITY)\n",
    "\n",
    "            NAME = ' '.join(''.join(RAW_NAME).split()) if RAW_NAME else None\n",
    "            SALE_PRICE = ' '.join(''.join(RAW_SALE_PRICE).split()).strip() if RAW_SALE_PRICE else None\n",
    "            CATEGORY = ' > '.join([i.strip() for i in RAW_CATEGORY]) if RAW_CATEGORY else None\n",
    "            ORIGINAL_PRICE = ''.join(RAW_ORIGINAL_PRICE).strip() if RAW_ORIGINAL_PRICE else None\n",
    "            AVAILABILITY = ''.join(RAw_AVAILABILITY).strip() if RAw_AVAILABILITY else None\n",
    "\n",
    "            if not ORIGINAL_PRICE:\n",
    "                ORIGINAL_PRICE = SALE_PRICE\n",
    "\n",
    "            if page.status_code!=200:\n",
    "                raise ValueError('captha')\n",
    "            data = {\n",
    "                    'NAME':NAME,\n",
    "                    'SALE_PRICE':SALE_PRICE,\n",
    "                    'CATEGORY':CATEGORY,\n",
    "                    'ORIGINAL_PRICE':ORIGINAL_PRICE,\n",
    "                    'AVAILABILITY':AVAILABILITY,\n",
    "                    'URL':url,\n",
    "                    }\n",
    "\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print e\n",
    "\n",
    "def ReadAsin():\n",
    "    # Add ASINs here by edit the AsinList Variable below\n",
    "    AsinList = ['B01EKSSKXG',\n",
    "    'B00JGTVU5A',\n",
    "    'B00GJYCIVK',\n",
    "    'B00EPGK7CQ',\n",
    "    'B00EPGKA4G',\n",
    "    'B00YW5DLB4',\n",
    "    'B00KGD0628',\n",
    "    'B00O9A48N2',\n",
    "    'B00O9A4MEW',\n",
    "    'B00UZKG8QU',]\n",
    "    extracted_data = []\n",
    "    for i in AsinList:\n",
    "        url = \"http://www.amazon.in/dp/\"+i\n",
    "        print \"Processing: \"+url\n",
    "        extracted_data.append(AmzonParser(url))\n",
    "        sleep(5)\n",
    "    f=open('data.json','w')\n",
    "    json.dump(extracted_data,f,indent=4)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ReadAsin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
